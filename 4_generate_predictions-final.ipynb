{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a6cc1-8ad0-4088-a733-85f0d72e7845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fa338dc-cc1a-42a4-93ed-16acf444029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "class EmbeddingClassifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_name: str,\n",
    "        window: str,\n",
    "        output_dir: str = \"./results\",\n",
    "        id_column: str = \"VariationID\",\n",
    "        label_column: str = \"is_pathogenic\"\n",
    "    ):\n",
    "        self.llm_name = llm_name\n",
    "        self.window = window\n",
    "        self.output_dir = output_dir\n",
    "        self.id_column = id_column\n",
    "        self.label_column = label_column\n",
    "        self.model_output_dir = os.path.join(output_dir, f\"{llm_name}_{window}\")\n",
    "        os.makedirs(self.model_output_dir, exist_ok=True)\n",
    "        # Mapping for classifier legend\n",
    "        self.classifier_display = {\n",
    "            \"LR\": \"Logistic Regression\",\n",
    "            \"XGB\": \"XGBoost\",\n",
    "            \"CAT\": \"CatBoost\",\n",
    "            \"LGBM\": \"LightGBM\"\n",
    "        }\n",
    "        self.classifiers = {\n",
    "            \"LR\": LogisticRegression(max_iter=500, class_weight=\"balanced\", random_state=42),\n",
    "            \"XGB\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "            \"CAT\": CatBoostClassifier(verbose=0, random_state=42),\n",
    "            \"LGBM\": LGBMClassifier(random_state=42)\n",
    "        }\n",
    "\n",
    "    def _path(self, stem, ext, clf=None):\n",
    "        # Helper to generate consistent filenames in the subfolder\n",
    "        if clf is not None:\n",
    "            return os.path.join(self.model_output_dir, f\"{self.llm_name}_{self.window}_{clf}_{stem}.{ext}\")\n",
    "        else:\n",
    "            return os.path.join(self.model_output_dir, f\"{self.llm_name}_{self.window}_{stem}.{ext}\")\n",
    "    \n",
    "    def plot_pca_elbow(self, pca, var_thresh=0.95):\n",
    "        cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "        n_components = int(np.argmax(cumvar >= var_thresh) + 1)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        x = np.arange(1, len(cumvar) + 1)\n",
    "        plt.plot(x, cumvar, marker=\"o\", label=\"Cumulative explained variance\")\n",
    "        plt.axvline(n_components, color=\"red\", linestyle=\"--\", label=f\"{n_components} components\")\n",
    "        plt.scatter([n_components], [cumvar[n_components - 1]], color=\"red\", zorder=5)\n",
    "        plt.axhline(var_thresh, color=\"gray\", linestyle=\":\", label=f\"{int(var_thresh*100)}% threshold\")\n",
    "        plt.xlabel(\"Number of PCA components\")\n",
    "        plt.ylabel(\"Cumulative explained variance\")\n",
    "        plt.title(f\"PCA Elbow: {self.llm_name} {self.window}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        fname = self._path(\"PCA_elbow\", \"png\")\n",
    "        plt.savefig(fname)\n",
    "        plt.close()\n",
    "        print(f\"PCA elbow plot saved to {fname}\")\n",
    "\n",
    "    def fit_pca_and_classifiers(\n",
    "        self,\n",
    "        train_meta: str,\n",
    "        train_emb: str,\n",
    "        pca_var: float = 0.95,\n",
    "        classifiers: list = None\n",
    "    ):\n",
    "        df = pd.read_csv(train_meta, sep=\"\\t\")\n",
    "        emb = pd.read_csv(train_emb)\n",
    "        train = df.merge(emb, on=self.id_column)\n",
    "        X = train.filter(like=\"emb_\").values\n",
    "        y = train[self.label_column].values\n",
    "\n",
    "        # 1. Fit PCA\n",
    "        pca = PCA(n_components=pca_var, random_state=42)\n",
    "        X_pca = pca.fit_transform(X)\n",
    "        pca_path = self._path(\"pca\", \"pkl\")\n",
    "        joblib.dump(pca, pca_path)\n",
    "        print(f\"Saved PCA model to {pca_path}, reduced to {X_pca.shape[1]} dims\")\n",
    "\n",
    "        # 2. Train and save classifiers\n",
    "        to_train = classifiers or list(self.classifiers.keys())\n",
    "        for clf_name in to_train:\n",
    "            clf = self.classifiers[clf_name]\n",
    "            clf.fit(X_pca, y)\n",
    "            clf_path = self._path(\"clf\", \"pkl\", clf=clf_name)\n",
    "            joblib.dump(clf, clf_path)\n",
    "            print(f\"Saved {clf_name} classifier to {clf_path}\")\n",
    "\n",
    "        # Optionally, save the reduced train set for auditing\n",
    "        pca_cols = [f'pca_{i+1}' for i in range(X_pca.shape[1])]\n",
    "        pca_df = pd.DataFrame(X_pca, columns=pca_cols, index=train.index)\n",
    "        train_reduced = pd.concat([train.reset_index(drop=True), pca_df.reset_index(drop=True)], axis=1)\n",
    "        train_reduced.to_csv(self._path(\"train_reduced\", \"csv\"), index=False)\n",
    "        print(f\"Saved reduced train set to {self._path('train_reduced', 'csv')}\")\n",
    "        # Plot PCA elbow\n",
    "        self.plot_pca_elbow(pca, var_thresh=pca_var)\n",
    "\n",
    "    def plot_all_metrics_grid(self, metrics_dict):\n",
    "        \"\"\"\n",
    "        Plot all metrics (precision, recall, f1-score, support) as grouped bar charts\n",
    "        for all classifiers, saved into a single 2x2 grid image.\n",
    "        The legend is shown once on the right of all subplots.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "    \n",
    "        metrics = ['precision', 'recall', 'f1-score', 'support']\n",
    "        example_metrics = next(iter(metrics_dict.values()))\n",
    "        exclude_keys = {\"accuracy\", \"macro avg\", \"weighted avg\"}\n",
    "        # Top-level keys are class labels (as strings) plus 'accuracy' etc.\n",
    "        class_labels = [k for k in example_metrics.keys() if k not in exclude_keys]\n",
    "        n_classes = len(class_labels)\n",
    "        x = np.arange(n_classes)\n",
    "        width = 0.18\n",
    "        clf_names = list(metrics_dict.keys())\n",
    "    \n",
    "        fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        axs = axs.flatten()\n",
    "        for i, metric in enumerate(metrics):\n",
    "            ax = axs[i]\n",
    "            for j, clf in enumerate(clf_names):\n",
    "                # For each class, get the metric value\n",
    "                vals = [metrics_dict[clf][cl][metric] for cl in class_labels]\n",
    "                ax.bar(x + j*width, vals, width, label=self.classifier_display.get(clf, clf))\n",
    "            ax.set_xticks(x + width * (len(clf_names) - 1) / 2)\n",
    "            ax.set_xticklabels(class_labels)\n",
    "            ax.set_ylabel(metric.capitalize())\n",
    "            ax.set_title(f'{metric.capitalize()} by Classifier')\n",
    "            # Do NOT call ax.legend() inside the loop\n",
    "    \n",
    "        # Place one legend for all plots to the right\n",
    "        handles, labels = axs[0].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, title=\"Classifier\", loc=\"center right\", bbox_to_anchor=(1.12, 0.5))\n",
    "        plt.tight_layout(rect=[0, 0, 0.93, 1])  # Make space for the legend on the right\n",
    "    \n",
    "        fname = os.path.join(self.model_output_dir, f\"{self.llm_name}_{self.window}_all_metrics_bar.png\")\n",
    "        plt.savefig(fname, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(f\"Saved all metrics bar grid to {fname}\")\n",
    "\n",
    "    def plot_all_confusion_matrices(self, y_true, y_preds_dict, class_names=None):\n",
    "        \"\"\"\n",
    "        Plot confusion matrices for each classifier in a 2x2 grid.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "    \n",
    "        n_clf = len(y_preds_dict)\n",
    "        nrows, ncols = 2, 2  # For up to 4 classifiers\n",
    "        fig, axs = plt.subplots(nrows, ncols, figsize=(12, 12))\n",
    "        axs = axs.flatten()\n",
    "        for i, (clf, y_pred) in enumerate(y_preds_dict.items()):\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
    "            disp.plot(ax=axs[i], colorbar=False)\n",
    "            axs[i].set_title(f\"Confusion Matrix: {clf}\")\n",
    "        # Hide unused axes if less than 4 classifiers\n",
    "        for j in range(i + 1, nrows * ncols):\n",
    "            fig.delaxes(axs[j])\n",
    "        plt.tight_layout()\n",
    "        fname = os.path.join(self.model_output_dir, f\"{self.llm_name}_{self.window}_all_confmats.png\")\n",
    "        plt.savefig(fname)\n",
    "        plt.close()\n",
    "        print(f\"Saved all confusion matrices to {fname}\")\n",
    "\n",
    "    def plot_roc_auc(self, y_true, y_probs_dict):\n",
    "        \"\"\"\n",
    "        Plots ROC curves for all classifiers.\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for clf, y_prob in y_probs_dict.items():\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, lw=2, label=f\"{self.classifier_display.get(clf, clf)} (AUC={roc_auc:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"ROC Curve: {self.llm_name} {self.window}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        plot_path = self._path(\"ROC\", \"png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved ROC curve plot to {plot_path}\")\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred, clf_name):\n",
    "        \"\"\"\n",
    "        Plots and saves the confusion matrix for a classifier.\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import ConfusionMatrixDisplay\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(cm)\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title(f\"Confusion Matrix: {self.classifier_display.get(clf_name, clf_name)}\")\n",
    "        plt.tight_layout()\n",
    "        plot_path = self._path(f\"confmat_{clf_name}\", \"png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved confusion matrix to {plot_path}\")\n",
    "\n",
    "    def save_classifier_legend(self):\n",
    "        legend_lines = [\n",
    "            \"Classifier Legend:\",\n",
    "            \"  CAT  - CatBoost\",\n",
    "            \"  LR   - Logistic Regression\",\n",
    "            \"  XGB  - XGBoost\",\n",
    "            \"  LGBM - LightGBM\"\n",
    "        ]\n",
    "        legend_txt = \"\\n\".join(legend_lines)\n",
    "        print(legend_txt)\n",
    "        with open(self._path(\"classifier_legend\", \"txt\"), \"w\") as f:\n",
    "            f.write(legend_txt)\n",
    "\n",
    "    def predict_and_eval(\n",
    "        self,\n",
    "        test_meta: str,\n",
    "        test_emb: str,\n",
    "        classifiers: list = None\n",
    "    ):\n",
    "        df = pd.read_csv(test_meta, sep=\"\\t\")\n",
    "        emb = pd.read_csv(test_emb)\n",
    "        test = df.merge(emb, on=self.id_column)\n",
    "        X = test.filter(like=\"emb_\").values\n",
    "        y = test[self.label_column].values\n",
    "\n",
    "        # 2. Load PCA and reduce test\n",
    "        pca = joblib.load(self._path(\"pca\", \"pkl\"))\n",
    "        X_pca = pca.transform(X)\n",
    "        print(f\"Test data reduced to {X_pca.shape[1]} dims\")\n",
    "\n",
    "        to_eval = classifiers or list(self.classifiers.keys())\n",
    "        metrics_dict = {}\n",
    "        y_probs_dict = {}\n",
    "        y_preds_dict = {}   # <-- NEW\n",
    "\n",
    "        for clf_name in to_eval:\n",
    "            clf = joblib.load(self._path(\"clf\", \"pkl\", clf=clf_name))\n",
    "            y_pred = clf.predict(X_pca)\n",
    "            y_preds_dict[clf_name] = y_pred  # <-- NEW\n",
    "            if hasattr(clf, \"predict_proba\"):\n",
    "                y_prob = clf.predict_proba(X_pca)[:, 1]\n",
    "            else:\n",
    "                y_prob = np.zeros_like(y_pred)\n",
    "            y_probs_dict[clf_name] = y_prob\n",
    "            cr = classification_report(y, y_pred, output_dict=True)\n",
    "            metrics_dict[clf_name] = cr\n",
    "            print(f\"\\n== {clf_name} on {self.llm_name} {self.window} ==\")\n",
    "            print(classification_report(y, y_pred, digits=3))\n",
    "            print(\"ROC AUC: %.3f\" % roc_auc_score(y, y_prob))\n",
    "            # Save predictions\n",
    "            test_cp = test.copy()\n",
    "            test_cp[\"prediction\"] = y_pred\n",
    "            test_cp[\"prob_pathogenic\"] = y_prob\n",
    "            pred_file = self._path(f\"predictions_test\", \"csv\", clf=clf_name)\n",
    "            test_cp.to_csv(pred_file, index=False)\n",
    "            print(f\"Saved predictions: {pred_file}\")\n",
    "            # Save confusion matrix\n",
    "            #self.plot_confusion_matrix(y, y_pred, clf_name)\n",
    "\n",
    "        # Visualize all metrics and confusion matrices in one file\n",
    "        self.plot_all_metrics_grid(metrics_dict)\n",
    "        self.plot_all_confusion_matrices(y, y_preds_dict, class_names=[\"Non-Pathogenic\", \"Pathogenic\"])\n",
    "        self.plot_roc_auc(y, y_probs_dict)\n",
    "        self.save_classifier_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12194c85-b792-499e-9ea2-4f7d5574c96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PCA model to ./results/NT_225bp/NT_225bp_pca.pkl, reduced to 398 dims\n",
      "Saved LR classifier to ./results/NT_225bp/NT_225bp_LR_clf.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/t131303uhn/anaconda3/envs/dna_bert2/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [13:45:15] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved XGB classifier to ./results/NT_225bp/NT_225bp_XGB_clf.pkl\n",
      "Saved CAT classifier to ./results/NT_225bp/NT_225bp_CAT_clf.pkl\n",
      "[LightGBM] [Info] Number of positive: 15000, number of negative: 15000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 101490\n",
      "[LightGBM] [Info] Number of data points in the train set: 30000, number of used features: 398\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Saved LGBM classifier to ./results/NT_225bp/NT_225bp_LGBM_clf.pkl\n",
      "Saved reduced train set to ./results/NT_225bp/NT_225bp_train_reduced.csv\n",
      "PCA elbow plot saved to ./results/NT_225bp/NT_225bp_PCA_elbow.png\n",
      "Test data reduced to 398 dims\n",
      "\n",
      "== LR on NT 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.713     0.703     0.708      1500\n",
      "           1      0.707     0.717     0.712      1500\n",
      "\n",
      "    accuracy                          0.710      3000\n",
      "   macro avg      0.710     0.710     0.710      3000\n",
      "weighted avg      0.710     0.710     0.710      3000\n",
      "\n",
      "ROC AUC: 0.775\n",
      "Saved predictions: ./results/NT_225bp/NT_225bp_LR_predictions_test.csv\n",
      "\n",
      "== XGB on NT 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.683     0.659     0.671      1500\n",
      "           1      0.671     0.695     0.683      1500\n",
      "\n",
      "    accuracy                          0.677      3000\n",
      "   macro avg      0.677     0.677     0.677      3000\n",
      "weighted avg      0.677     0.677     0.677      3000\n",
      "\n",
      "ROC AUC: 0.742\n",
      "Saved predictions: ./results/NT_225bp/NT_225bp_XGB_predictions_test.csv\n",
      "\n",
      "== CAT on NT 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.705     0.670     0.687      1500\n",
      "           1      0.686     0.719     0.702      1500\n",
      "\n",
      "    accuracy                          0.695      3000\n",
      "   macro avg      0.695     0.695     0.694      3000\n",
      "weighted avg      0.695     0.695     0.694      3000\n",
      "\n",
      "ROC AUC: 0.763\n",
      "Saved predictions: ./results/NT_225bp/NT_225bp_CAT_predictions_test.csv\n",
      "\n",
      "== LGBM on NT 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.683     0.664     0.673      1500\n",
      "           1      0.673     0.691     0.682      1500\n",
      "\n",
      "    accuracy                          0.678      3000\n",
      "   macro avg      0.678     0.678     0.678      3000\n",
      "weighted avg      0.678     0.678     0.678      3000\n",
      "\n",
      "ROC AUC: 0.744\n",
      "Saved predictions: ./results/NT_225bp/NT_225bp_LGBM_predictions_test.csv\n",
      "Saved all metrics bar grid to ./results/NT_225bp/NT_225bp_all_metrics_bar.png\n",
      "Saved all confusion matrices to ./results/NT_225bp/NT_225bp_all_confmats.png\n",
      "Saved ROC curve plot to ./results/NT_225bp/NT_225bp_ROC.png\n",
      "Classifier Legend:\n",
      "  CAT  - CatBoost\n",
      "  LR   - Logistic Regression\n",
      "  XGB  - XGBoost\n",
      "  LGBM - LightGBM\n"
     ]
    }
   ],
   "source": [
    "classifier = EmbeddingClassifier(llm_name=\"NT\", window=\"225bp\", output_dir=\"./results\")\n",
    "classifier.fit_pca_and_classifiers(\n",
    "    train_meta=\"./data/windows_225/clinvar_binary_train_225.tsv\",\n",
    "    train_emb=\"./data/embeddings/clinvar_binary_train_embeddings_NT_225.csv\",\n",
    "    pca_var=0.95,  # retain 95% variance\n",
    "    classifiers=[\"LR\", \"XGB\", \"CAT\", \"LGBM\"]  # Run all, or just pick your subset\n",
    ")\n",
    "\n",
    "# Evaluate on holdout (test) set\n",
    "classifier.predict_and_eval(\n",
    "    test_meta=\"./data/windows_225/clinvar_binary_test_225.tsv\",\n",
    "    test_emb=\"./data/embeddings/clinvar_binary_test_embeddings_NT_225.csv\",\n",
    "    classifiers=[\"LR\", \"XGB\", \"CAT\", \"LGBM\"]  # Must match what you trained!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e1ce8e3-04d9-4443-bbd4-92e19ac482ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PCA model to ./results/DNABERT6_225bp/DNABERT6_225bp_pca.pkl, reduced to 38 dims\n",
      "Saved LR classifier to ./results/DNABERT6_225bp/DNABERT6_225bp_LR_clf.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/t131303uhn/anaconda3/envs/dna_bert2/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [13:46:58] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved XGB classifier to ./results/DNABERT6_225bp/DNABERT6_225bp_XGB_clf.pkl\n",
      "Saved CAT classifier to ./results/DNABERT6_225bp/DNABERT6_225bp_CAT_clf.pkl\n",
      "[LightGBM] [Info] Number of positive: 15000, number of negative: 15000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9690\n",
      "[LightGBM] [Info] Number of data points in the train set: 30000, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Saved LGBM classifier to ./results/DNABERT6_225bp/DNABERT6_225bp_LGBM_clf.pkl\n",
      "Saved reduced train set to ./results/DNABERT6_225bp/DNABERT6_225bp_train_reduced.csv\n",
      "PCA elbow plot saved to ./results/DNABERT6_225bp/DNABERT6_225bp_PCA_elbow.png\n",
      "Test data reduced to 38 dims\n",
      "\n",
      "== LR on DNABERT6 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.540     0.485     0.511      1500\n",
      "           1      0.532     0.586     0.558      1500\n",
      "\n",
      "    accuracy                          0.536      3000\n",
      "   macro avg      0.536     0.536     0.534      3000\n",
      "weighted avg      0.536     0.536     0.534      3000\n",
      "\n",
      "ROC AUC: 0.553\n",
      "Saved predictions: ./results/DNABERT6_225bp/DNABERT6_225bp_LR_predictions_test.csv\n",
      "\n",
      "== XGB on DNABERT6 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.565     0.537     0.551      1500\n",
      "           1      0.559     0.587     0.573      1500\n",
      "\n",
      "    accuracy                          0.562      3000\n",
      "   macro avg      0.562     0.562     0.562      3000\n",
      "weighted avg      0.562     0.562     0.562      3000\n",
      "\n",
      "ROC AUC: 0.577\n",
      "Saved predictions: ./results/DNABERT6_225bp/DNABERT6_225bp_XGB_predictions_test.csv\n",
      "\n",
      "== CAT on DNABERT6 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.563     0.528     0.545      1500\n",
      "           1      0.556     0.590     0.572      1500\n",
      "\n",
      "    accuracy                          0.559      3000\n",
      "   macro avg      0.559     0.559     0.559      3000\n",
      "weighted avg      0.559     0.559     0.559      3000\n",
      "\n",
      "ROC AUC: 0.590\n",
      "Saved predictions: ./results/DNABERT6_225bp/DNABERT6_225bp_CAT_predictions_test.csv\n",
      "\n",
      "== LGBM on DNABERT6 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.553     0.504     0.527      1500\n",
      "           1      0.544     0.593     0.568      1500\n",
      "\n",
      "    accuracy                          0.548      3000\n",
      "   macro avg      0.549     0.548     0.547      3000\n",
      "weighted avg      0.549     0.548     0.547      3000\n",
      "\n",
      "ROC AUC: 0.573\n",
      "Saved predictions: ./results/DNABERT6_225bp/DNABERT6_225bp_LGBM_predictions_test.csv\n",
      "Saved all metrics bar grid to ./results/DNABERT6_225bp/DNABERT6_225bp_all_metrics_bar.png\n",
      "Saved all confusion matrices to ./results/DNABERT6_225bp/DNABERT6_225bp_all_confmats.png\n",
      "Saved ROC curve plot to ./results/DNABERT6_225bp/DNABERT6_225bp_ROC.png\n",
      "Classifier Legend:\n",
      "  CAT  - CatBoost\n",
      "  LR   - Logistic Regression\n",
      "  XGB  - XGBoost\n",
      "  LGBM - LightGBM\n"
     ]
    }
   ],
   "source": [
    "# Train (fit PCA and all 4 classifiers on train set)\n",
    "classifier = EmbeddingClassifier(llm_name=\"DNABERT6\", window=\"225bp\", output_dir=\"./results\")\n",
    "classifier.fit_pca_and_classifiers(\n",
    "    train_meta=\"./data/windows_225/clinvar_binary_train_225.tsv\",\n",
    "    train_emb=\"./data/embeddings/clinvar_binary_train_embeddings_DNABERT6_225.csv\",\n",
    "    pca_var=0.95,  # retain 95% variance\n",
    "    classifiers=[\"LR\", \"XGB\", \"CAT\", \"LGBM\"]  # Run all, or just pick your subset\n",
    ")\n",
    "\n",
    "# Evaluate on holdout (test) set\n",
    "classifier.predict_and_eval(\n",
    "    test_meta=\"./data/windows_225/clinvar_binary_test_225.tsv\",\n",
    "    test_emb=\"./data/embeddings/clinvar_binary_test_embeddings_DNABERT6_225.csv\",\n",
    "    classifiers=[\"LR\", \"XGB\", \"CAT\", \"LGBM\"]  # Must match what you trained!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0bf93c7-459d-4057-b0cc-1c6aeb742ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PCA model to ./results/GROVER_225bp/GROVER_225bp_pca.pkl, reduced to 184 dims\n",
      "Saved LR classifier to ./results/GROVER_225bp/GROVER_225bp_LR_clf.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/t131303uhn/anaconda3/envs/dna_bert2/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [13:47:47] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved XGB classifier to ./results/GROVER_225bp/GROVER_225bp_XGB_clf.pkl\n",
      "Saved CAT classifier to ./results/GROVER_225bp/GROVER_225bp_CAT_clf.pkl\n",
      "[LightGBM] [Info] Number of positive: 15000, number of negative: 15000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46920\n",
      "[LightGBM] [Info] Number of data points in the train set: 30000, number of used features: 184\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Saved LGBM classifier to ./results/GROVER_225bp/GROVER_225bp_LGBM_clf.pkl\n",
      "Saved reduced train set to ./results/GROVER_225bp/GROVER_225bp_train_reduced.csv\n",
      "PCA elbow plot saved to ./results/GROVER_225bp/GROVER_225bp_PCA_elbow.png\n",
      "Test data reduced to 184 dims\n",
      "\n",
      "== LR on GROVER 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.573     0.547     0.559      1500\n",
      "           1      0.566     0.592     0.579      1500\n",
      "\n",
      "    accuracy                          0.569      3000\n",
      "   macro avg      0.569     0.569     0.569      3000\n",
      "weighted avg      0.569     0.569     0.569      3000\n",
      "\n",
      "ROC AUC: 0.601\n",
      "Saved predictions: ./results/GROVER_225bp/GROVER_225bp_LR_predictions_test.csv\n",
      "\n",
      "== XGB on GROVER 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.588     0.568     0.578      1500\n",
      "           1      0.582     0.602     0.592      1500\n",
      "\n",
      "    accuracy                          0.585      3000\n",
      "   macro avg      0.585     0.585     0.585      3000\n",
      "weighted avg      0.585     0.585     0.585      3000\n",
      "\n",
      "ROC AUC: 0.618\n",
      "Saved predictions: ./results/GROVER_225bp/GROVER_225bp_XGB_predictions_test.csv\n",
      "\n",
      "== CAT on GROVER 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.586     0.547     0.566      1500\n",
      "           1      0.575     0.613     0.593      1500\n",
      "\n",
      "    accuracy                          0.580      3000\n",
      "   macro avg      0.580     0.580     0.580      3000\n",
      "weighted avg      0.580     0.580     0.580      3000\n",
      "\n",
      "ROC AUC: 0.614\n",
      "Saved predictions: ./results/GROVER_225bp/GROVER_225bp_CAT_predictions_test.csv\n",
      "\n",
      "== LGBM on GROVER 225bp ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.585     0.547     0.565      1500\n",
      "           1      0.574     0.612     0.593      1500\n",
      "\n",
      "    accuracy                          0.579      3000\n",
      "   macro avg      0.580     0.579     0.579      3000\n",
      "weighted avg      0.580     0.579     0.579      3000\n",
      "\n",
      "ROC AUC: 0.613\n",
      "Saved predictions: ./results/GROVER_225bp/GROVER_225bp_LGBM_predictions_test.csv\n",
      "Saved all metrics bar grid to ./results/GROVER_225bp/GROVER_225bp_all_metrics_bar.png\n",
      "Saved all confusion matrices to ./results/GROVER_225bp/GROVER_225bp_all_confmats.png\n",
      "Saved ROC curve plot to ./results/GROVER_225bp/GROVER_225bp_ROC.png\n",
      "Classifier Legend:\n",
      "  CAT  - CatBoost\n",
      "  LR   - Logistic Regression\n",
      "  XGB  - XGBoost\n",
      "  LGBM - LightGBM\n"
     ]
    }
   ],
   "source": [
    "# Train (fit PCA and all 4 classifiers on train set)\n",
    "classifier = EmbeddingClassifier(llm_name=\"GROVER\", window=\"225bp\", output_dir=\"./results\")\n",
    "classifier.fit_pca_and_classifiers(\n",
    "    train_meta=\"./data/windows_225/clinvar_binary_train_225.tsv\",\n",
    "    train_emb=\"./data/embeddings/clinvar_binary_train_embeddings_GROVER_225.csv\",\n",
    "    pca_var=0.95,  # retain 95% variance\n",
    "    classifiers=[\"LR\", \"XGB\", \"CAT\", \"LGBM\"]  # Run all, or just pick your subset\n",
    ")\n",
    "\n",
    "# Evaluate on holdout (test) set\n",
    "classifier.predict_and_eval(\n",
    "    test_meta=\"./data/windows_225/clinvar_binary_test_225.tsv\",\n",
    "    test_emb=\"./data/embeddings/clinvar_binary_test_embeddings_GROVER_225.csv\",\n",
    "    classifiers=[\"LR\", \"XGB\", \"CAT\", \"LGBM\"]  # Must match what you trained!\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
